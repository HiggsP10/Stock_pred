{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Pick the best Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\joesc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\joesc\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "c:\\Users\\joesc\\anaconda3\\envs\\stock_pred\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen, Request\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import AdamW\n",
    "import sys \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# sys.path.append(os.path.abspath(\"/Users/13793/Desktop/aas/stock\"))\n",
    "\n",
    "\n",
    "# Add the project root directory to the Python path\n",
    "import subprocess\n",
    "result = subprocess.check_output([\"git\", \"rev-parse\", \"--show-toplevel\"], universal_newlines=True)\n",
    "git_root = result.strip()\n",
    "sys.path.append(git_root)\n",
    "\n",
    "from src import processer as processer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the raw data with 'processer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joesc\\anaconda3\\envs\\stock_pred\\Lib\\site-packages\\pandas\\core\\strings\\object_array.py:172: FutureWarning: Possible nested set at position 1\n",
      "  pat = re.compile(pat, flags=flags)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kickers watchlist xide tit soq pnk cpw bpz aj ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aap movie 55 percent return fea geed indicator...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id afraid short amzn looking like near monopol...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mnta 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oi 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>industry body cii said likely suffer net reven...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>prices slip below rs 46000 book profits amid l...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>workers bajaj auto agreed 10 percent wage cut ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>live sensex days high up 600 points tests 92...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>climb days highs still up 2 percent key factor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5791 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "0     kickers watchlist xide tit soq pnk cpw bpz aj ...          1\n",
       "1     aap movie 55 percent return fea geed indicator...          1\n",
       "2     id afraid short amzn looking like near monopol...          1\n",
       "3                                            mnta 12.00          1\n",
       "4                                              oi 21.37          1\n",
       "...                                                 ...        ...\n",
       "5786  industry body cii said likely suffer net reven...         -1\n",
       "5787  prices slip below rs 46000 book profits amid l...         -1\n",
       "5788  workers bajaj auto agreed 10 percent wage cut ...          1\n",
       "5789  live sensex days high up 600 points tests 92...          1\n",
       "5790  climb days highs still up 2 percent key factor...          1\n",
       "\n",
       "[5791 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trained the model by a data set with text and sentiment\n",
    "data = pd.read_csv('../data/twitter.csv', encoding='ISO-8859-1')\n",
    "data = processer.Preprocess_Tweets(data)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three Models: \n",
    "\n",
    "1. Base Line vader Sentiment analysis model\n",
    "\n",
    "2. Naive Bayesian model\n",
    "\n",
    "3. BERT NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader Accuracy: 66.14 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SentimentIntensityAnalyzer()\n",
    "#baseline\n",
    "data['V_score'] = data['Text'].apply(lambda score: model.polarity_scores(score)['compound'])\n",
    "data['V_prediction'] = data['V_score'].apply(lambda score: 1 if score>=0 else -1)\n",
    "print('Vader Accuracy:', round((len(data[data['Sentiment']==data['V_prediction']])/len(data)) *100, 2), '%', '\\n')\n",
    "Stats = []\n",
    "Stats.append(round((len(data[data['Sentiment']==data['V_prediction']])/len(data)) *100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha:  0.6   |  Best Score:  84.35\n",
      "Naive-Bayes Accuracy: 71.7 %\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayesian Train/Test\n",
    "train_pct = .8\n",
    "np.random.seed(100)\n",
    "idx = np.random.permutation(len(data))\n",
    "\n",
    "X_train = data['Text'].values[idx[:int(train_pct*len(data))]]\n",
    "y_train = data['Sentiment'].values[idx[:int(train_pct*len(data))]]\n",
    "y_train[y_train==-1] = 0\n",
    "X_test = data['Text'].values[idx[int(train_pct*len(data)):]]\n",
    "y_test = data['Sentiment'].values[idx[int(train_pct*len(data)):]]\n",
    "y_test[y_test==-1] = 0\n",
    "\n",
    "# Calculate TF-IDF for Naive Bayes classification\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                         binary=True,\n",
    "                         smooth_idf=False)\n",
    "X_train_tfidf = tf_idf.fit_transform(X_train)\n",
    "X_test_tfidf = tf_idf.transform(X_test)\n",
    "\n",
    "\n",
    "# Define AreaUnderCurve function to determine accuracy of model\n",
    "def auc_CV(model):\n",
    "    kf = StratifiedKFold(5, shuffle=True, random_state=1)\n",
    "\n",
    "    auc = cross_val_score(model, X_train_tfidf, y_train, scoring=\"roc_auc\", cv=kf)\n",
    "\n",
    "    return auc.mean()\n",
    "\n",
    "# Find best performing model\n",
    "alphas = np.arange(0.4,1.5,0.1)\n",
    "models = [MultinomialNB(alpha=i) for i in alphas]\n",
    "accs = []\n",
    "for model in models:\n",
    "    accs.append(auc_CV(model))\n",
    "accs = np.array(accs)\n",
    "best_alpha = round(alphas[accs.argmax()], 1)\n",
    "\n",
    "# Print best alpha value and accuracy\n",
    "print('Best alpha: ', best_alpha, '  |  Best Score: ', round(accs.max()*100, 2))\n",
    "\n",
    "# Retrain best performing model\n",
    "best_model = MultinomialNB(alpha=best_alpha)\n",
    "best_model.fit(X_train_tfidf, y_train)\n",
    "probs = best_model.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Print accuracy of best performing model on tweet sentiment analysis \n",
    "print('Naive-Bayes Accuracy:', round(len(np.where(y_test == probs.argmax(axis=1))[0])/len(probs) * 100, 2), '%')\n",
    "Stats.append(round(len(np.where(y_test == probs.argmax(axis=1))[0])/len(probs) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes Accuracy (K-Fold): 71.804 %\n"
     ]
    }
   ],
   "source": [
    "#K-Fold\n",
    "kfold = KFold(n_splits=5,\n",
    "                 shuffle=True,\n",
    "                 random_state=132)\n",
    "mses = np.zeros((1, 5))\n",
    "i=0\n",
    "for train_index, test_index in kfold.split(data):\n",
    "    X_train = data.loc[train_index]['Text']\n",
    "    y_train = data.loc[train_index]['Sentiment']\n",
    "    y_train[y_train==-1] = 0\n",
    "    X_test = data.loc[test_index]['Text']\n",
    "    y_test = data.loc[test_index]['Sentiment']\n",
    "    y_test[y_test==-1] = 0\n",
    "    \n",
    "    # Calculate TF-IDF for Naive Bayes classification\n",
    "    tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                         binary=True,\n",
    "                         smooth_idf=False)\n",
    "    X_train_tfidf = tf_idf.fit_transform(X_train)\n",
    "    X_test_tfidf = tf_idf.transform(X_test)\n",
    " \n",
    "    #Use the best model\n",
    "    best_model = MultinomialNB(alpha=0.6)\n",
    "    best_model.fit(X_train_tfidf, y_train)\n",
    "    probs = best_model.predict_proba(X_test_tfidf)\n",
    "   \n",
    "    mses[0,i] = round(len(np.where(y_test == probs.argmax(axis=1))[0])/len(probs) * 100, 2)\n",
    "    i=i+1\n",
    "print('Naive-Bayes Accuracy (K-Fold):', mses.mean(), '%')\n",
    "Stats.append(mses.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "train_pct = .8\n",
    "np.random.seed(10)\n",
    "idx = np.random.permutation(len(data))\n",
    "\n",
    "X_train = data['Text'].values[idx[:int(train_pct*len(data))]]\n",
    "y_train = data['Sentiment'].values[idx[:int(train_pct*len(data))]]\n",
    "y_train[y_train==-1] = 0\n",
    "X_test = data['Text'].values[idx[int(train_pct*len(data)):]]\n",
    "y_test = data['Sentiment'].values[idx[int(train_pct*len(data)):]]\n",
    "y_test[y_test==-1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joesc\\anaconda3\\envs\\stock_pred\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT processing function\n",
    "def prep(data):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    #encode data\n",
    "    for i in data:\n",
    "        encoding = tokenizer.encode_plus(\n",
    "                text=i, \n",
    "                add_special_tokens=True, \n",
    "                padding='max_length', \n",
    "                max_length = MAX_LEN, \n",
    "                truncation=True, \n",
    "                return_tensors=\"pt\", \n",
    "                return_attention_mask=True )\n",
    "\n",
    "        # add the encodings to the list\n",
    "        input_ids.append(encoding.get('input_ids'))\n",
    "        attention_masks.append(encoding.get('attention_mask'))\n",
    "    \n",
    "    # return the lists as tensors\n",
    "    input_ids = torch.concat(input_ids)\n",
    "    attention_masks = torch.concat(attention_masks)\n",
    "    \n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  48\n"
     ]
    }
   ],
   "source": [
    "#Setting up for BERT\n",
    "encoded = [tokenizer.encode(i, add_special_tokens=True) for i in data['Text'].values]\n",
    "MAX_LEN = max([len(i) for i in encoded])\n",
    "print('Max length: ', MAX_LEN)\n",
    "X_train_inputs, X_train_masks = prep(X_train)\n",
    "X_test_inputs, X_test_masks = prep(X_test)\n",
    "y_train_labels = torch.tensor(y_train)\n",
    "y_test_labels = torch.tensor(y_test)\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_data = TensorDataset(X_train_inputs, X_train_masks, y_train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "test_data = TensorDataset(X_test_inputs, X_test_masks, y_test_labels)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Bert NLP Classifier\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, freeze=False):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        input_layer = 768\n",
    "        hidden_layer = 40\n",
    "        output_layer = 2\n",
    "\n",
    "        # Use the pretrained Bert model for first section of NN\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Define a final layer to attach to the Bert model for custom classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_layer, hidden_layer), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_layer, output_layer))\n",
    "\n",
    "        # Freeze the model from updating\n",
    "        if freeze:\n",
    "            for i in self.bert.parameters():\n",
    "                i.requires_grad = False\n",
    "        \n",
    "    # Return classification from Bert model \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask)\n",
    "        layer = outputs[0][:, 0, :]\n",
    "        logits = self.classifier(layer)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed_all(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# Check if GPU is available and assign device \n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joesc\\anaconda3\\envs\\stock_pred\\Lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\joesc\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "model = BertClassifier(freeze=False)\n",
    "model.to(device)\n",
    "\n",
    "# Define model hyperparameters\n",
    "epochs = 4\n",
    "steps = len(train_dataloader) * epochs\n",
    "lr = 8e-5\n",
    "eps = 1e-8\n",
    "optimizer = AdamW(model.parameters(), lr=lr, eps=eps)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=steps)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "for e in range(epochs):\n",
    "    # Assign model to train\n",
    "    model.train()\n",
    "\n",
    "    # Intialize loss to zero\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        batch_inputs, batch_masks, batch_labels = batch\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_masks = batch_masks.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        # Reset the model gradient\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Get classification of encoded values\n",
    "        logits = model(batch_inputs, batch_masks)\n",
    "        \n",
    "        # Calculate loss based on predictions and known values\n",
    "        loss = loss_function(logits, batch_labels)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over batch\n",
    "    train_loss /= len(train_dataloader)\n",
    "    \n",
    "    # Assign the model to evaluate    \n",
    "    model.eval()\n",
    "\n",
    "    # Initialize losses\n",
    "    test_loss = 0\n",
    "    test_acc = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        batch_inputs, batch_masks, batch_labels = batch\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_masks = batch_masks.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(batch_inputs, batch_masks)\n",
    "        loss = loss_function(logits, batch_labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Convert predictions to 0 and 1 Notice:Here 0/1 is enough, detailed sentiment score could derive at overfitting\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate accuracy of model on test data; NOTICE: this accuracy function has to align with previous models\n",
    "        accuracy = (preds == batch_labels).cpu().numpy().mean() * 100\n",
    "        test_acc += accuracy\n",
    "\n",
    "    # Calculate average loss and accuracy per each batch\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "    print('Epoch: %d  |  Train Loss: %1.5f  |  Test Loss: %1.5f  |  Test Accuracy: %1.2f'%(e+1, train_loss, test_loss, test_acc))\n",
    "    \n",
    "torch.save(model.state_dict(), 'stock_sentiment_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for negative sentiment:  76.22377622377621 %\n",
      "Accuracy for positive sentiment:  86.43835616438355 %\n",
      "Accuracy for total sentiment:  82.65746333045729 %\n"
     ]
    }
   ],
   "source": [
    "#Check BERT accuracy\n",
    "model = BertClassifier(freeze=False)\n",
    "model.load_state_dict(torch.load('stock_sentiment_model.pt'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for batch in test_dataloader:\n",
    "    batch_inputs, batch_masks, batch_labels = batch\n",
    "\n",
    "    batch_inputs = batch_inputs.to(device)\n",
    "    batch_masks = batch_masks.to(device)\n",
    "    batch_labels = batch_labels.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(batch_inputs, batch_masks)\n",
    "\n",
    "\n",
    "    preds = torch.argmax(logits, dim=1).flatten()\n",
    "    predictions.append(preds)\n",
    "        \n",
    "predictions = torch.cat(predictions).cpu().numpy()\n",
    "\n",
    "#Due to this phenomenon, later we designed two scores 1/2 for positive sentiment\n",
    "negatives = np.where(y_test==0)[0]\n",
    "TNs = np.where( (y_test==0) & (y_test==predictions) )[0]\n",
    "print('Accuracy for negative sentiment: ',(len(TNs)/len(negatives))*100,'%')\n",
    "Stats.append((len(TNs)/len(negatives))*100)\n",
    "positives = np.where(y_test==1)[0]\n",
    "TPs = np.where( (y_test==1) & (y_test==predictions) )[0]\n",
    "print('Accuracy for positive sentiment: ',(len(TPs)/len(positives))*100,'%')\n",
    "Stats.append((len(TPs)/len(positives))*100)\n",
    "TT = np.where( (y_test==predictions) )[0]\n",
    "print('Accuracy for total sentiment: ',(len(TT)/len(y_test))*100,'%')\n",
    "Stats.append((len(TT)/len(y_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10, 5))\n",
    "ModelType = ['Baseline Vader', 'Naive Bayesian','Naive Bayesian K-Fold','BERT negative', 'BERT positive', 'BERT']\n",
    "# creating the bar plot\n",
    "plt.bar(ModelType, Stats, color ='maroon', \n",
    "        width = 0.4)\n",
    "\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accurary\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT model perform the best, we choose BERT for the next step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
