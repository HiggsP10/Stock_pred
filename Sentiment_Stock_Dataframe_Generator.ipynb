{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torch.optim import AdamW\n",
    "import sys \n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"/Users/13793/Desktop/aas/stock\"))\n",
    "import processer as processer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)\n",
    "MAX_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT processing function\n",
    "def prep(data):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    \n",
    "    for i in data:\n",
    "        encoding = tokenizer.encode_plus(\n",
    "                text=i, \n",
    "                add_special_tokens=True, # adds special chars [CLS] and [SEP] to encoding \n",
    "                padding='max_length', # pad the tweets with 0s to fit max length\n",
    "                max_length = MAX_LEN, # assign max length\n",
    "                truncation=True, \n",
    "                return_tensors=\"pt\", \n",
    "                return_attention_mask=True )\n",
    "\n",
    "        # add the encodings to the list\n",
    "        input_ids.append(encoding.get('input_ids'))\n",
    "        attention_masks.append(encoding.get('attention_mask'))\n",
    "    \n",
    "    # return the lists as tensors\n",
    "    input_ids = torch.concat(input_ids)\n",
    "    attention_masks = torch.concat(attention_masks)\n",
    "    \n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Bert NLP Classifier\n",
    "class BertClassifier(nn.Module):\n",
    "    def __init__(self, freeze=False):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        input_layer = 768\n",
    "        hidden_layer = 40\n",
    "        output_layer = 2\n",
    "\n",
    "        # Use the pretrained Bert model for first section of NN\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Define a final layer to attach to the Bert model for custom classification\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(input_layer, hidden_layer), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(hidden_layer, output_layer))\n",
    "\n",
    "        # Freeze the model from updating\n",
    "        if freeze:\n",
    "            for i in self.bert.parameters():\n",
    "                i.requires_grad = False\n",
    "        \n",
    "    # Return classification from Bert model \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids, attention_mask)\n",
    "        layer = outputs[0][:, 0, :]\n",
    "        logits = self.classifier(layer)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=40, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=40, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if GPU is available and assign device \n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "model = BertClassifier(freeze=False)\n",
    "model.load_state_dict(torch.load('stock_sentiment_model.pt'))\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\13793\\anaconda3\\Lib\\site-packages\\pandas\\core\\strings\\object_array.py:172: FutureWarning: Possible nested set at position 1\n",
      "  pat = re.compile(pat, flags=flags)\n",
      "c:\\Users\\13793\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aal - completed\n"
     ]
    }
   ],
   "source": [
    "# Get the list of stock data to convert\n",
    "files = os.listdir('data/')\n",
    "\n",
    "# for each stock files\n",
    "for x in range(len(files)):\n",
    "    # open the excel file on the Stream sheet\n",
    "    stock = pd.read_excel('data/'+files[x] + '/export_dashboard_' + files[x], sheet_name='Stream')\n",
    "\n",
    "    # Assign the ticker name as a column\n",
    "    stock['Ticker'] = files[x].split('_')[0]\n",
    "    \n",
    "    # Convert string date times to datetime\n",
    "    stock['Date'] = pd.to_datetime(stock['Date'])\n",
    "    stock['Hour'] = stock['Hour'].apply(lambda t: pd.Timedelta(hours=int(t[:2]), minutes=int(t[3:])))\n",
    "    stock['Datetime'] = stock['Date'] + stock['Hour']\n",
    "\n",
    "    # Rename column that holds the tweets content\n",
    "    stock.rename(columns = {'Tweet content':'Text'}, inplace = True)\n",
    "\n",
    "    # Pre process the tweet content\n",
    "    stock = processer.Preprocess_Tweets(stock)\n",
    "\n",
    "    # Remove excess columns\n",
    "    stock = stock[['Tweet Id', 'Ticker', 'Datetime', 'Text', 'Favs', 'RTs', 'Followers', 'Following', 'Is a RT']]\n",
    "    \n",
    "    # Fill NAs in Favs, RTs, Followers and Following with 0\n",
    "    stock = stock.fillna(0)\n",
    "\n",
    "    # Encode processed tweets for Bert NLP model\n",
    "    stock_inputs, stock_masks = prep(stock['Text'].values)\n",
    "\n",
    "    batch_size = 16\n",
    "    # Put stock data in PyTorch dataloader for processing \n",
    "    stock_data = TensorDataset(stock_inputs, stock_masks)\n",
    "    stock_sampler = RandomSampler(stock_data)\n",
    "    stock_dataloader = DataLoader(stock_data, sampler=stock_sampler, batch_size=batch_size)\n",
    "\n",
    "    # Assign model to evaluate \n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    # For each batch\n",
    "    for batch in stock_dataloader:\n",
    "        # Get encoded inputs and masks \n",
    "        batch_inputs, batch_masks = batch\n",
    "\n",
    "        # Send variables to device (GPU if available)\n",
    "        batch_inputs = batch_inputs.to(device)\n",
    "        batch_masks = batch_masks.to(device)\n",
    "\n",
    "        # Predict classes with Bert for given inputs \n",
    "        with torch.no_grad():\n",
    "            logits = model(batch_inputs, batch_masks)\n",
    "\n",
    "        # Convert predictions to 0s and 1s\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "        predictions.append(preds)\n",
    "\n",
    "    # Combine all batch predictions\n",
    "    predictions = torch.cat(predictions).cpu().numpy()\n",
    "    \n",
    "    # Add predictions to stock dataframe\n",
    "    stock['Sentiment'] = predictions\n",
    "    \n",
    "    # save predictions as new csv\n",
    "    stock.to_csv('data/'+files[x] +'/stock_data_sentiment.csv', index=False)\n",
    "    \n",
    "    # Show stock names as they are completed \n",
    "    print(files[x].split('_')[0], '- completed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>Text</th>\n",
       "      <th>Favs</th>\n",
       "      <th>RTs</th>\n",
       "      <th>Followers</th>\n",
       "      <th>Following</th>\n",
       "      <th>Is a RT</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>743011665663295491</td>\n",
       "      <td>aal</td>\n",
       "      <td>2016-06-15 09:26:00</td>\n",
       "      <td>american airlines group inc aal novo nordisk n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2039.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>742994700563558400</td>\n",
       "      <td>aal</td>\n",
       "      <td>2016-06-15 08:18:00</td>\n",
       "      <td>yesterdays top fallers anglo american aal anto...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1792.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>742991573181423618</td>\n",
       "      <td>aal</td>\n",
       "      <td>2016-06-15 08:06:00</td>\n",
       "      <td>saquickideas 5 large cap stocks lowest enterpr...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>742991250899513345</td>\n",
       "      <td>aal</td>\n",
       "      <td>2016-06-15 08:04:00</td>\n",
       "      <td>jpmorgan chase co reiterates underweight ratin...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>771.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>742990282380173313</td>\n",
       "      <td>aal</td>\n",
       "      <td>2016-06-15 08:01:00</td>\n",
       "      <td>dal aal 5 large cap stocks lowest enterprise m...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>788.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6502</th>\n",
       "      <td>707914551908552705</td>\n",
       "      <td>aal</td>\n",
       "      <td>2016-03-10 13:02:00</td>\n",
       "      <td>u vie 4 flights</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>248.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6503</th>\n",
       "      <td>707908040348016640</td>\n",
       "      <td>aal</td>\n",
       "      <td>2016-03-10 12:36:00</td>\n",
       "      <td>new stock pick psnp picking up serious attenti...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12543.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6504</th>\n",
       "      <td>707907421889495040</td>\n",
       "      <td>aal</td>\n",
       "      <td>2016-03-10 12:34:00</td>\n",
       "      <td>hot new stock alert psnp things really poised ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19713.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6505</th>\n",
       "      <td>707906875690512385</td>\n",
       "      <td>aal</td>\n",
       "      <td>2016-03-10 12:32:00</td>\n",
       "      <td>mineral exploration company heating up fast se...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12556.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6506</th>\n",
       "      <td>707859062738669569</td>\n",
       "      <td>aal</td>\n",
       "      <td>2016-03-10 09:22:00</td>\n",
       "      <td>aal exchange see greater aal mitk anth</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6507 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Tweet Id Ticker            Datetime  \\\n",
       "0     743011665663295491    aal 2016-06-15 09:26:00   \n",
       "1     742994700563558400    aal 2016-06-15 08:18:00   \n",
       "2     742991573181423618    aal 2016-06-15 08:06:00   \n",
       "3     742991250899513345    aal 2016-06-15 08:04:00   \n",
       "4     742990282380173313    aal 2016-06-15 08:01:00   \n",
       "...                  ...    ...                 ...   \n",
       "6502  707914551908552705    aal 2016-03-10 13:02:00   \n",
       "6503  707908040348016640    aal 2016-03-10 12:36:00   \n",
       "6504  707907421889495040    aal 2016-03-10 12:34:00   \n",
       "6505  707906875690512385    aal 2016-03-10 12:32:00   \n",
       "6506  707859062738669569    aal 2016-03-10 09:22:00   \n",
       "\n",
       "                                                   Text  Favs  RTs  Followers  \\\n",
       "0     american airlines group inc aal novo nordisk n...   0.0  0.0     2039.0   \n",
       "1     yesterdays top fallers anglo american aal anto...   0.0  0.0     1792.0   \n",
       "2     saquickideas 5 large cap stocks lowest enterpr...   0.0  0.0     1589.0   \n",
       "3     jpmorgan chase co reiterates underweight ratin...   0.0  0.0      771.0   \n",
       "4     dal aal 5 large cap stocks lowest enterprise m...   0.0  0.0      788.0   \n",
       "...                                                 ...   ...  ...        ...   \n",
       "6502                                    u vie 4 flights   1.0  0.0      248.0   \n",
       "6503  new stock pick psnp picking up serious attenti...   0.0  0.0    12543.0   \n",
       "6504  hot new stock alert psnp things really poised ...   0.0  0.0    19713.0   \n",
       "6505  mineral exploration company heating up fast se...   0.0  0.0    12556.0   \n",
       "6506             aal exchange see greater aal mitk anth   0.0  0.0       19.0   \n",
       "\n",
       "      Following  Is a RT  Sentiment  \n",
       "0         108.0    False          1  \n",
       "1          80.0    False          0  \n",
       "2        1376.0    False          1  \n",
       "3           8.0    False          0  \n",
       "4           6.0    False          1  \n",
       "...         ...      ...        ...  \n",
       "6502      156.0    False          1  \n",
       "6503        0.0    False          0  \n",
       "6504        0.0    False          1  \n",
       "6505        0.0    False          1  \n",
       "6506       40.0    False          0  \n",
       "\n",
       "[6507 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
